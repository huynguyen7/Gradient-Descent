{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation:\n",
    "- Vanilla Gradient Descent.\n",
    "- Graphing vectors (Grad vectors / Jacobian vectors) through each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "- This implementation applies only for functions which have 2 variables only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines functions\n",
    "f = lambda x, y : x**2 + y**2\n",
    "dfdx = lambda x, y: 2*x\n",
    "dfdy = lambda x, y: 2*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphs Contour plot for f(x, y).\n",
    "def graph_contour():\n",
    "    x_space = np.linspace(-5, 5, 100)\n",
    "    y_space = np.linspace(-5, 5, 100)\n",
    "    [X, Y] = np.meshgrid(x_space, y_space)\n",
    "    fig, axes = plt.subplots(1, 1)\n",
    "\n",
    "    # fill contour plot \n",
    "    axes.contourf(X, Y, f(X, Y)) \n",
    "    axes.set_title('Contour Plot')\n",
    "    axes.set_xlabel('x') \n",
    "    axes.set_ylabel('y') \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# Graphs f(x,y) in 3D dimension.\n",
    "def graph_3D():\n",
    "    x_space = np.array(range(-5,5))\n",
    "    y_space = np.array(range(-5,5))\n",
    "    x, y = np.meshgrid(x_space, y_space)\n",
    "    fig = plt.figure()\n",
    "    axes = fig.gca(projection=\"3d\")\n",
    "    axes.plot_surface(x, y, f(x, y), cmap=\"rainbow\")\n",
    "    axes.set_title('3D Dimension')\n",
    "    axes.set_xlabel('x')\n",
    "    axes.set_ylabel('y')\n",
    "    axes.set_zlabel('f(x,y)')\n",
    "    plt.contour(x, y, f(x, y), cmap=\"rainbow\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_3d(x_start, y_start, max_iteraton=10, eta=0.05, threshold=0.001, plot=False):\n",
    "    # Plot 2D representation of array with starting point as a red marker\n",
    "    if plot:\n",
    "        x_space = np.linspace(-5, 5, 100)\n",
    "        y_space = np.linspace(-5, 5, 100)\n",
    "        [X, Y] = np.meshgrid(x_space, y_space)\n",
    "        fig, axes = plt.subplots(1, 1)\n",
    "        plt.plot(x_start, y_start, 'r+')\n",
    "        \n",
    "        # fill contour plot \n",
    "        axes.contourf(X, Y, f(X, Y)) \n",
    "        axes.set_title('Contour Plot')\n",
    "        axes.set_xlabel('x') \n",
    "        axes.set_ylabel('y')\n",
    "    \n",
    "    curr_x = x_start\n",
    "    curr_y = y_start\n",
    "    curr_min = None\n",
    "    \n",
    "    vector_modulus = lambda x, y: math.sqrt(x**2 + y**2)\n",
    "    global_min = vector_modulus(x_start, y_start)\n",
    "    \n",
    "    # Apply Gradient Descent\n",
    "    for i in range(1, max_iteration + 1):\n",
    "                \n",
    "        prev_x = curr_x\n",
    "        prev_y = curr_y\n",
    "        \n",
    "        curr_x = curr_x - eta * dfdx(curr_x, curr_y)\n",
    "        curr_y = curr_y - eta * dfdy(curr_y, curr_y)\n",
    "        curr_min = vector_modulus(curr_x, curr_y)\n",
    "\n",
    "        if (prev_x == curr_x and prev_y == curr_y) or (global_min - curr_min <= threshold):\n",
    "            print(f\"f(x, y) converged in {i} steps with starting point at ({x_start}, {y_start}) with threshold={threshold}\")\n",
    "            break\n",
    "        elif global_min > curr_min:\n",
    "            global_min = curr_min\n",
    "        # print(f\"ITER: {i} with GLOBAL_MIN = {global_min}, CURR_MIN = {curr_min}, isEqual = {global_min == curr_min}\")\n",
    "        \n",
    "        if plot:\n",
    "            plt.plot([curr_x, prev_x], [curr_y, prev_y],marker = '.')\n",
    "    if plot:\n",
    "        plt.show()\n",
    "    print(f\"ITER: {i} with GLOBAL_MIN = {global_min}, CURR_MIN = {curr_min}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic graphs\n",
    "graph_contour()\n",
    "graph_3D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines variables\n",
    "x_start = 2 # starting x coordinate\n",
    "y_start = 3 # starting y coordinate\n",
    "max_iteration = 20 # number of steps\n",
    "eta = 0.17 # learning rate\n",
    "threshold = 0.005 # Tell the algorithm when to stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Gradient Descent Algorithm.\n",
    "gradient_descent_3d(x_start, y_start, max_iteration, eta, threshold, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
